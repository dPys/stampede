#!/bin/sh
#set -x
#SLURM auto-submission job wrapper customized by Derek Pisner and Chad Cumba for use with
#FSL on Stampede and Lonestar5 at the Texas Advanced Computing Center (TACC). 9-19-2016
###########################ORIGINAL COPYRIGHT##############################
# Copyright (C) 2007-2014 University of Oxford
# Authors: Dave Flitney, Stephen Smith, Matthew Webster and Duncan Mortimer
#
#   Part of FSL - FMRIB's Software Library
#   http://www.fmrib.ox.ac.uk/fsl
#   fsl@fmrib.ox.ac.uk
#
#   Developed at FMRIB (Oxford Centre for Functional Magnetic Resonance
#   Imaging of the Brain), Department of Clinical Neurology, Oxford
#   University, Oxford, UK
#
#
#   LICENCE
#
#   FMRIB Software Library, Release 5.0 (c) 2012, The University of
#   Oxford (the "Software")
#
#   The Software remains the property of the University of Oxford ("the
#   University").
#
#   The Software is distributed "AS IS" under this Licence solely for
#   non-commercial use in the hope that it will be useful, but in order
#   that the University as a charitable foundation protects its assets for
#   the benefit of its educational and research purposes, the University
#   makes clear that no condition is made or to be implied, nor is any
#   warranty given or to be implied, as to the accuracy of the Software,
#   or that it will be suitable for any particular purpose or for use
#   under any specific conditions. Furthermore, the University disclaims
#   all responsibility for the use which is made of the Software. It
#   further disclaims any liability for the outcomes arising from using
#   the Software.
#
#   The Licensee agrees to indemnify the University and hold the
#   University harmless from and against any and all claims, damages and
#   liabilities asserted by third parties (including claims for
#   negligence) which arise directly or indirectly from the use of the
#   Software or the sale of any products based on the Software.
#
#   No part of the Software may be reproduced, modified, transmitted or
#   transferred in any form or by any means, electronic or mechanical,
#   without the express permission of the University. The permission of
#   the University is not required if the said reproduction, modification,
#   transmission or transference is done without financial return, the
#   conditions of this Licence are imposed upon the receiver of the
#   product, and all original and amended source code is included in any
#   transmitted product. You may be held legally responsible for any
#   copyright infringement that is caused or encouraged by your failure to
#   abide by these terms and conditions.
#   The Licensee agrees to indemnify the University and hold the
#   University harmless from and against any and all claims, damages and
#   liabilities asserted by third parties (including claims for
#   negligence) which arise directly or indirectly from the use of the
#   Software or the sale of any products based on the Software.
#
#   No part of the Software may be reproduced, modified, transmitted or
#   transferred in any form or by any means, electronic or mechanical,
#   without the express permission of the University. The permission of
#   the University is not required if the said reproduction, modification,
#   transmission or transference is done without financial return, the
#   conditions of this Licence are imposed upon the receiver of the
#   product, and all original and amended source code is included in any
#   transmitted product. You may be held legally responsible for any
#   copyright infringement that is caused or encouraged by your failure to
#   abide by these terms and conditions.
#
#   You are not permitted under this Licence to use this Software
#   commercially. Use for which any financial return is received shall be
#   defined as commercial use, and includes (1) integration of all or part
#   of the source code or the Software into a product for sale or license
#   by or on behalf of Licensee to third parties or (2) use of the
#   Software or any derivative of it for research with the final aim of
#   developing software products for sale or license to a third party or
#   (3) use of the Software or any derivative of it for research with the
#   final aim of developing non-software products for sale or license to a
#   third party, or (4) use of the Software to provide any service to an
#   external organisation for which payment is received. If you are
#   interested in using the Software commercially, please contact Isis
#   Innovation Limited ("Isis"), the technology transfer company of the
#   University, to negotiate a licence. Contact details are:
#   innovation@isis.ox.ac.uk quoting reference DE/9564.
###########################ORIGINAL COPYRIGHT##############################

export LC_ALL=C

if [ "x$METHOD" = "x" ]; then
    METHOD="SLURM"
fi

##Stop submitted scripts from submitting jobs themselves
if [ "X$FSLSUBALREADYRUN" = "Xtrue" ] ; then
    METHOD=NONE
    echo "Warning: job on queue attempted to submit parallel jobs - running jobs serially instead" >&2
fi

FSLSUBALREADYRUN=true
export FSLSUBALREADYRUN

##Default GPU threads
gpu_threads=4

##Project allocation name
allocation='Machine-learning-app'

##Default WALLTIME (in minutes) for: 1) normal, largemem, development, and gpu queues; and 2) the serial queue
default_WALLTIME=120
default_WALLTIME_VERYLONG=480

##Relevant Modules and paths
#source ~/.bashrc
if [[ `hostname -d` == 'stampede.tacc.utexas.edu' ]]; then
    module load launcher/2.0 2>/dev/null
    export TACC_LAUNCHER_DIR=/opt/apps/launcher/launcher-2.0
    host='stampede'
    ##Number of cores per node
    numcores_per_node=16
elif [[ `hostname -d` == 'ls5.tacc.utexas.edu' ]]; then
    module load launcher/3.0.1
    export TACC_LAUNCHER_DIR=/opt/apps/launcher/3.0.1
    host='ls5'
    ##Number of cores per node
    numcores_per_node=24
fi

###########################################################################
###########################################################################

POSIXLY_CORRECT=1
export POSIXLY_CORRECT
command=`basename $0`

usage ()
{
  cat <<EOF
Parallelization wrapper for SLURM job control system
Usage: $command [options] <command>
  -T <minutes>          Estimated job length in minutes, used to auto-set queue name
  -q <queuename>        Possible values for <queuename> are "serial", "largemem"
  -A <your allocation>  Name of your allocation project (e.g. IRC_MRI)
  -t <filename>         Specify a task file of commands to execute in parallel
  -M <email-address>    Send job information to email address
  -m <mail options>     notify on state change: BEGIN, END, FAIL or ALL
  -j <jid>              Place a hold on this task until job jid has completed
  -N <jobname>          Specify jobname as it will appear on queue
  -s <pename>,<threads/tasks> Submit a multi-threaded task - (available pe's
                        are: mpi, omp_pe, and serial)
  -l <logdirname>       Where to output logfiles
  -v                    Verbose mode.
Queues:
There are 5 batch queues configured on the cluster, each with defined CPU
time limits.
serial:	This queue is for jobs which do not explicitly run parallel code and last longer than 2h.
normal:    This queue is for jobs which last up to 2h (or 24 h+, if serial <pename> is set).
large:  This queue is for jobs which require high virtual memory, and which last up to 2h.
development:    This queue is for jobs that run functions for testing, and which last up to 2h.
gpu:       This queue is for jobs which employ cuda-enabled functions, and which last up to 2h.
EOF

  exit 1
}

nargs=$#
if [ $nargs -eq 0 ] ; then
    usage
fi

set -- `getopt z:T:q:A:s:M:j:t:m:N:l:v $*`
result=$?
if [ $result != 0 ] ; then
    echo "Argument Invalid. Try again."
fi

if [ $nargs -eq 0 ] || [ $result != 0 ] ; then
    usage
fi

###########################################################################
# The following sets up the default queue name, which you may want to
# change. It also sets up the basic emailing control.
###########################################################################

mailto=`whoami`@utexas.edu

if [ -z $FSLSUBVERBOSE ] ; then
    verbose=0
else
    verbose=$FSLSUBVERBOSE;
    echo "METHOD=$METHOD : args="$@"" >&2
fi

# Can remove after full test
verbose=1
###########################################################################
# getopts options
###########################################################################

while [ $1 != -- ] ; do
  case $1 in
    -z)
      if [ -e $2 -o `${FSLDIR}/bin/imtest $2` = 1 ] ; then
        exit 0
      fi
      shift;;
    -T)
      WALLTIME=$2
      shift;;
    -q)
      queue=$2
      shift;;
    -A)
      allocation=$2; 
      allocation_exp="-A $allocation"
      shift;;
    -s)
      pe_string=$2;
      peName=`echo $pe_string | cut -d',' -f 1`
      if [[ "$peName" != [^a-zA-Z0-9] ]]; then
          peName=""
      fi
      peThreads=`echo $pe_string | cut -d',' -f 2`
      shift;;
    -M)
      mailto=$2
      if [ -z $mailto ]; then
          mailto=`whoami`@utexas.edu
      fi
      shift;;
    -j)
      jid=$2
      if [[ $jid =~ ^.*[0-9]+.*$ ]] ; then
        jid=$(echo $jid | sed -e 's/,/:/g')
      fi
      slurm_hold="--dependency=afterok:"$jid""
      shift;;
    -t)
      taskfile=$2
      if [ -f "$taskfile" ] ; then
          tasks=`wc -l $taskfile | awk '{print $1}'`
	  SCRIPT=`echo $(readlink -f "$taskfile")`
	  workingdir=`dirname $SCRIPT`
	  go_parametric=1
          if [ $tasks -ne 0 ]; then
            slurm_tasks="-t 1-$tasks"
          else
            echo "Task file ${taskfile} is empty"
            echo "Should be a text file listing all the commands to run!"
            exit -1
          fi
      else
          echo "Task file (${taskfile}) does not exist"
          exit -1
      fi
      go_parametric=1
      shift;;
    -m)
      MailOpts=$2;
      shift;;
    -N)
      JobName=$2;
      shift;;
    -l)
      LogOpts="-o $2/%j -e $2/%j";
      shift;;
    -v)
      verbose=1
      ;;
  esac
  shift
done
shift

unset POSIXLY_CORRECT

###########################################################################
if [ -z "$taskfile" ] && [ -z "$1" ]; then
        echo "Either supply a command to run or a parallel task file"
        exit -1
fi

if [ -z "$taskfile" ] && [ ! -x "$1" ]; then
        which $1 >/dev/null 2>&1
        if [ $? -ne 0 ]; then
                echo "The command you have requested cannot be found or is not executable"
                exit -1
        fi
fi

if [ "x$JobName" = x ] ; then
    if [ "x$taskfile" != x ] ; then
        JobName=`basename $taskfile`
    else
        JobName=`basename $1`
    fi
fi

if [ "x$tasks" != "x" ] && [ "x$@" != "x" ] ; then
    echo "Spurious input after parsing command line: \"$@\"!"
    echo "You appear to have specified both a task file and a command to run"
    exit -1
fi

###############Configure environment for parallel computing and auto-decide job submission parameters

##Default to normal queue if none specified
if [ -z $queue ]; then
    queue=normal
fi

##Set WALLTIME to default when not manually supplied
if [ -z $WALLTIME ]; then
    if [[ $queue == normal ]] || [[ $queue == largemem ]] || [[ $queue == development ]] || [[ $queue == gpu ]]; then
        WALLTIME=$default_WALLTIME
    fi
fi

if [[ $queue == largemem ]]; then
    if [[ `hostname -d` == 'ls5.tacc.utexas.edu' ]]; then
	module load TACC-largemem 2>/dev/null
    fi
else
    module load TACC 2>/dev/null
    export TACC_LAUNCHER_SCHED=interleaved
fi

##Check and configure serial job situations (first when pe is set serial, second when queue is set to serial)
if [[ $peName == serial ]] && [ -z $WALLTIME ]; then
    queue=serial
    WALLTIME=$default_WALLTIME_VERYLONG
fi

if [[ $queue == serial ]] && [ -z $WALLTIME ]; then
    WALLTIME=$default_WALLTIME_VERYLONG
fi

##Set default peThreads if empty
re='^[0-9]+$'
if [ -z $peThreads ] || ! [[ $peThreads =~ $re ]]; then
    peThreads=8
fi

##Set allocation to default if empty
if [ -z $allocation ]; then
    allocation=$2;
fi

allocation_exp="-A $allocation"

##Handle Email alert flags
if [ ! -z $mailto ]; then
    ##Default to FAIL alerts only if no email options specified
    if [ -z $MailOpts ]; then
	MailOpts='FAIL'
    fi
    mail_flags="--mail-user=$mailto --mail-type=$MailOpts"
fi

if [ -z $JobName ]; then
   JobName=fsl_sub
fi

#echo "$peThreads"
#echo "$peName"
#echo "$JOB_ID"
#echo "$queue"
#exit 0

case $METHOD in

########################################################################
# The following is the main call to the cluster, using SLURM
###########################################################################

    SLURM)
        ###########################################################################
        #Set parallel environment
        ###########################################################################
	##Calculate number of cores per node hyperthreaded
        numcores_per_node_hyperthreaded=`echo "$numcores_per_node * 2" | bc`
        if [ ! -z $peName ] && [ ! -z $peThreads ]; then
	    ##Parametric Launcher jobs
	    if [[ $peName == mpi ]] && [[ $go_parametric == 1 ]]; then
		##Get number of tasks from taskfile
                num_tasks=`cat "$taskfile" | wc -l`	
		    
		##Calculate total number of threads being called across each individual job submission
		cores_total=`echo "$num_tasks * $peThreads" | bc`

		##Get number of nodes to cover the number of tasks x number of threads per task	    
		node_num=`echo "$cores_total / $numcores_per_node + 1" | bc`		

                ##Set pe_option
                pe_option="-n $numcores_per_node -N $node_num"

	    ##MPI jobs
            elif [[ $peName == mpi ]]; then
                ##Get number of nodes to cover the number of threads
                node_num=`echo "$peThreads / $numcores_per_node + 1" | bc`
		
		##Recalculate peThreads to an inflated number of cores as a multiple of 16
		cores_total=`echo "$node_num * 16" | bc`

                ##Set pe_option
                pe_option="-n $numcores_per_node -N $node_num"

            ##Serial and OpenMP Jobs
            elif [[ $peName == omp_pe ]] && [[ $go_parametric == 1 ]]; then
                ##Get number of tasks from taskfile
                num_tasks=`cat "$taskfile" | wc -l`

                ##Calculate total number of threads being called across each individual job submission
                cores_total=`echo "$num_tasks * $peThreads" | bc`

                openMP=`export OMP_NUM_THREADS=$cores_total`
                node_num=1
                pe_option="-N 1 -n $cores_total"
            elif [[ $peName == omp_pe ]]; then
                openMP=`export OMP_NUM_THREADS=$peThreads`
                node_num=1
                pe_option="-N 1 -n $peThreads"
	    elif  [[ $peName == serial ]]; then
		queue=serial
                node_num=1
                pe_option="-N 1 -n $peThreads"
	    elif [[ $queue == gpu ]]; then
                node_num=1
                pe_option="-N 1 -n $gpu_threads"  
	    fi
	elif [ -z $peName ] && [ ! -z $peThreads ]; then
	    node_num=`echo "$peThreads / $numcores_per_node + 1" | bc`
	    pe_option="-N $node_num -n $peThreads"
	elif [ -z $peName ] && [ -z $peThreads ]; then
	    node_num=1
	    pe_option="-N 1 -n $numcores_per_node_hyperthreaded"
        fi

	#walltime in minutes
        WALLTIME=`echo "$WALLTIME * 60" | bc`

	#walltime in hh:mm:ss
	WALLTIME_neat=`printf '%d:%d:%d\n' $(($WALLTIME/3600)) $(($WALLTIME%3600/60)) $(($WALLTIME%60))`

	if [[ $go_parametric != 1 ]]; then
            if [ $verbose -eq 1 ] ; then
                echo slurm_command: $slurm_command >&2
		echo executing: $@ >&2
                ##Print submission parameters
            	echo -e "\n"
            	echo -e "\033[1;32mRunning FSL using $METHOD on cluster: \033[m \033[1;31m $host \033[m"
            	echo -e "\033[1;32mNumber of compute nodes to allocate: \033[m \033[1;31m $node_num \033[m"
            	echo -e "\033[1;32mJob name: \033[m \033[1;31m $JobName \033[m"
            	echo -e "\033[1;32mName of the submission queue: \033[m \033[1;31m $queue \033[m"
            	echo -e "\033[1;32mMax time the job is alloted to run (hh:mm:ss): \033[m \033[1;31m "$WALLTIME_neat" \033[m"
            	echo -e "\033[1;32mNumber of cores requested: \033[m \033[1;31m $peThreads \033[m"
            	echo -e "\033[1;32mAllocation: \033[m \033[1;31m $allocation \033[m"
            	echo -e "\n"
            fi
	    if [[ $peName == mpi ]]; then
                slurm_command_mpi="sbatch --get-user-env $mail_flags -p $queue $pe_option $allocation_exp -J $JobName $logOpts -t $WALLTIME_neat $slurm_hold ibrun -n $peThreads --wrap=\""$@"\""
      		exec $slurm_command_mpi
	    else
                slurm_command="sbatch --get-user-env $mail_flags -p $queue $pe_option $allocation_exp -J $JobName $logOpts -t $WALLTIME_neat $slurm_hold --wrap=\""$@"\""
                rand_num=$RANDOM
		echo -e "#!/bin/bash\n"$openMP"\n"$slurm_command"" > $FSLDIR/jobs/"$JobName"_job_"$rand_num".sh
		chmod a+x $FSLDIR/jobs/"$JobName"_job_"$rand_num".sh
		$FSLDIR/jobs/"$JobName"_job_"$rand_num".sh
	    fi
        elif [[ $go_parametric == 1 ]]; then
	    if [[ $tasks < 1 ]]; then
		echo "ERROR: No tasks specified in taskfile!"
		exit -1 
	    fi
            slurm_command="sbatch --get-user-env $mail_flags -p $queue $pe_option $allocation_exp -J $JobName $logOpts -t $WALLTIME_neat $slurm_hold"
            if [ $verbose -eq 1 ] ; then
                echo slurm_command: "$slurm_command" >&2
                echo control file: "$taskfile" >&2
                ##Print submission parameters
                echo -e "\n"
                echo -e "\033[1;32mRunning FSL using $METHOD on cluster: \033[m \033[1;31m $host \033[m"
                echo -e "\033[1;32mNumber of compute nodes to allocate: \033[m \033[1;31m $node_num \033[m"
                echo -e "\033[1;32mJob name: \033[m \033[1;31m $JobName \033[m"
                echo -e "\033[1;32mName of the submission queue: \033[m \033[1;31m $queue \033[m"
                echo -e "\033[1;32mMax time the job is alloted to run (hh:mm:ss): \033[m \033[1;31m "$WALLTIME_neat" \033[m"
                echo -e "\033[1;32mNumber of cores requested: \033[m \033[1;31m $peThreads \033[m"
                echo -e "\033[1;32mAllocation: \033[m \033[1;31m $allocation \033[m"
                echo -e "\n"
            fi
	    #export TACC_LAUNCHER_PPN="$numcores_per_node"
	    export LAUNCHER_PPN="$numcores_per_node"
	    export EXECUTABLE=$TACC_LAUNCHER_DIR/init_launcher
	    export LAUNCHER_WORKDIR=$workingdir
	    export LAUNCHER_JOB_FILE=$taskfile
	    export LAUNCHER_NJOBS=`cat "$LAUNCHER_JOB_FILE" | wc -l`
	    #export TACC_LAUNCHER_SCHED=dynamic
	    export LAUNCHER_SCHED=dynamic
	    export LAUNCHER_NPROCS=$peThreads
	    $slurm_command $TACC_LAUNCHER_DIR/paramrun SLURM $EXECUTABLE $LAUNCHER_WORKDIR $LAUNCHER_JOB_FILE
        fi
        ;;


    NONE)
        if [ "x$tasks" = "x" ] ; then
            if [ $verbose -eq 1 ] ; then 
                echo executing: $@ >&2
            fi

            /bin/sh <<EOF1 > ${LogDir}${JobName}.o$$ 2> ${LogDir}${JobName}.e$$
$@
EOF1
            ERR=$?
            if [ $ERR -ne 0 ] ; then
                cat ${LogDir}${JobName}.e$$ >&2
                exit $ERR
            fi
        else
            if [ $verbose -eq 1 ] ; then 
                echo "Running commands in: $taskfile" >&2
            fi

            n=1
            while [ $n -le $tasks ] ; do
                line=`sed -n -e ''${n}'p' $taskfile`
                if [ $verbose -eq 1 ] ; then 
                    echo executing: $line >&2
                fi
                /bin/sh <<EOF2 > ${LogDir}${JobName}.o$$.$n 2> ${LogDir}${JobName}.e$$.$n
$line
EOF2
                n=`expr $n + 1`
            done
        fi      
        echo $$
        ;;

esac
